{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67c05a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing steps:\n",
    "# ========================\n",
    "\n",
    "# missing values handle\n",
    "# outliers\n",
    "# data transform\n",
    "# scaling\n",
    "# data reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9411c56",
   "metadata": {},
   "source": [
    "TRAINING MODEL \n",
    "=============\n",
    "\n",
    "1. # import python,numpy\n",
    "\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "2. # data set to dataframe\n",
    "\n",
    "data = pandas.read_csv('diabetes.csv')\n",
    "df = pandas.DataFrame(data)\n",
    "df \n",
    "\n",
    "3. # set the target \n",
    "\n",
    "target >>>>> outcome\n",
    "input features >>>\n",
    "\n",
    "4. # drop the columns that is not needed\n",
    "   # df.dropna() used to remove the rows with missing value\n",
    "\n",
    "df = df.drop('id',axis = 1)\n",
    "             or\n",
    "df = df.drop(columns=['Age','Sex'],axis=1)\n",
    "\n",
    "\n",
    "5. # find the missing values\n",
    "   df.isna()   used to find is there any missing value \n",
    "\n",
    "df.isna().sum()\n",
    "\n",
    "6. # if missing value present fill with fillna\n",
    "   # df.fillna() used to fill the misssing value\n",
    "\n",
    "df['trestbps'].fillna(df['trestbps'].mean(),inplace=True)\n",
    "                        or\n",
    "df['trestbps'] = df['trestbps'].fillna(df['trestbps'].mean())\n",
    "   \n",
    "df['bp_category'].fillna(df['bp_category'].mode()[0],inplace= True)      >>>>>> here mode[0] - [0] value is taken\n",
    "                        or\n",
    "df['Dependents'] =df['Dependents'].fillna(df['Dependents'].mode()[0])\n",
    "\n",
    "7. # check any object present and if present convert to numerical - encoding\n",
    "   # encoding >>>> convert to appropriate integer value\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder      # ML concept in sklearn\n",
    "le = LabelEncoder()\n",
    "df['ChestPainType'] = le.fit_transform(df['ChestPainType'])   # fit >> collect   , transform >> transform  or fit_transform \n",
    "                                       or\n",
    "df['Stock'] = df['Stock'].map({'In Stock' : 0,'Out of Stock' : 1})   # encoding  >>>> data preprocessing  \n",
    "\n",
    "8. # scikit-learn\n",
    "   # separating input features and target\n",
    "   # x contains input features and y contains target\n",
    "\n",
    "X = df.iloc[:,:-1]\n",
    "Y = df.iloc[:,-1]\n",
    "# loc - Access a group of rows and columns by label(s) or a boolean array.  loc[row,column]\n",
    "\n",
    "9. # next step :  spliting the data into training(70%) and test(30%)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size= 0.3)\n",
    "\n",
    "10. # after the splitting the next step is scaling\n",
    "\n",
    "# scaling          \n",
    "# -------\n",
    "getting every values in the dataframe to a similar range is called scaling\n",
    "\n",
    "there are two type scaling : \n",
    "\n",
    "# <----standard scaler---->\n",
    "Z = (X - mean) / standard deviation\n",
    "Z = resulted scaled value\n",
    "x = input from training data\n",
    "mean = mean of the column where x has been taken\n",
    "standard deviation = std of the column\n",
    "\n",
    "# <----min max scaler----->\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()       # we have to create an object for standard deviation\n",
    "                                # y_test and y_train already in the range 0 - 1\n",
    "scaler.fit(X_train)             # only the x_train need to fit here values taken ...so if x_test taken data leakage will happens\n",
    "                                # here data taken find mean and standard deviation\n",
    "X_train = scaler.transform(X_train)  # here scaling to a range(like 0 - 1)\n",
    "X_test = scaler.transform(X_test)  # to avoid the data leakage we put X_test into transform directly\n",
    "\n",
    "\n",
    "11. # algorithm\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier   # KNN class\n",
    "knn = KNeighborsClassifier()                         # k = 5  odd number 5 7 \n",
    "knn = knn.fit(X_train,Y_train)                       # train hte model using the 70% input features and 70% result\n",
    "#here knn is the model\n",
    "y_pred = knn.predict(X_test)                         # predict the result for the unseen data(x_test)\n",
    "#30% input , 30% output\n",
    "y_pred\n",
    "\n",
    "\n",
    "12. # accuracy score \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_pred,Y_test))\n",
    "\n",
    "13. confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(Y_test,y_pred)\n",
    "cm      #TruePositive - 128 TrueNegative - 22  FalsePositive - 39 FalseNegative - 42\n",
    "\n",
    "# model performance evaluating methods\n",
    "\n",
    "# accuracy_score\n",
    "#================\n",
    "' accuracy = correct predictions / total predictions'\n",
    "\n",
    "# recall\n",
    "#=========\n",
    "''\n",
    "\n",
    "# f1_score\n",
    "#=========\n",
    "'mean of precision and recall'\n",
    "\n",
    "# precision\n",
    "#==========\n",
    "'out of all predicted result how many are correct'\n",
    "\n",
    "\n",
    "# supervised learning  >>> classification\n",
    "# confusion matrix     >>> TruePositive TrueNegative FalsePositive FalseNegative\n",
    "\n",
    "# TruePositive \n",
    "# 0      0\n",
    "# TrueNegative \n",
    "# 1      1\n",
    "# FalsePositive\n",
    "# 1      0\n",
    "#  FalseNegative\n",
    "# 0      1\n",
    "\n",
    "\"\"\"\n",
    "[TP  FP \n",
    " FN  TN]\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decb8b4f",
   "metadata": {},
   "source": [
    "# iloc for accessing the index if data frame is not labelled\n",
    "\n",
    "d = {\"name\": [\"a\",\"b\",\"c\"],\n",
    "     \"age\" : [2,3,4]}\n",
    "\n",
    "df1 = pandas.DataFrame(d,index=[\"r1\",\"r2\",\"r3\"])\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22f0d50",
   "metadata": {},
   "source": [
    "# display the type (int,object...) \n",
    "df.dtypes\n",
    "\n",
    "# display the first 5 rows of dataset\n",
    "df.head()\n",
    "\n",
    "# dispaly the last 5 rows\n",
    "df.tail()   \n",
    "\n",
    "# show the shape of dataset\n",
    "df.shape\n",
    "\n",
    "# getting the standard deviation\n",
    "df.describe()\n",
    "\n",
    "# df = df.dropna(subset= 'Rating')\n",
    "\n",
    "# find the average cholestrol by gender\n",
    "# df.groupby('sex').mean()\n",
    "df.groupby('sex')['chol'].mean()\n",
    "\n",
    "# find the top 5 patients with the highest cholestrol values\n",
    "# highest values in column = outliers / extrem\n",
    "# .nlargest() → a pandas function that returns the top n rows with the largest values in one or more specified columns\n",
    "df.nlargest(n = 5,columns = ['chol'])\n",
    "\n",
    "# Find how many unique values each column has.\n",
    "df.nunique()     # returns the number of unique values in each column\n",
    "\n",
    "# Sort the dataset by age in descending order and display top 10 records.\n",
    "df.sort_values(by='age', ascending=False).head(10)\n",
    "\n",
    "# Find the correlation between all numeric columns.\n",
    "df.corr()\n",
    "\n",
    "# Create a new column chol_status → “High” if chol > 240 else “Normal”.\n",
    "df['chol_status'] = df['chol'].apply(lambda a: \"high\" if a > 240 else \"normal\")\n",
    "\n",
    "# Find all items that have a Discount greater than 20% but Price less than 1000.\n",
    "df[(df[\"Discount\"] > 20) & (df['Price'] < 1000)]\n",
    "\n",
    "# Display only Price and Rating columns for the first 10 items.\n",
    "df.loc[:,['Price','Rating']].head(10)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
